{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Random Forest.(학생용).ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"knw6Ww264ZQ2"},"source":["# Random Forest\n","Random Forest는 패턴 추출을 위한 feature를 임의로 선택하여 복수의 Decision Tree를 만드는 알고리즘 입니다. 임의의 데이터를 Randomd Forest에 입력하면 각각의 Decision Tree에서의 결과를 voting하여 class를 할당합니다. Sklearn에서 제공하는 Random Forest 모델을 이용하여 실습을 진행해봅시다."]},{"cell_type":"code","metadata":{"id":"fZwIFSD04f1V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623995950478,"user_tz":-540,"elapsed":5736,"user":{"displayName":"Potter Harry","photoUrl":"","userId":"17463850288633486562"}},"outputId":"c65608d7-246c-47cd-861e-544729b126d0"},"source":["!pip install mglearn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mglearn\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/8aced26fce0b2ae82c3c87cd3b6105f38ca6d9d51704ecc44aa54473e6b9/mglearn-0.1.9.tar.gz (540kB)\n","\u001b[K     |████████████████████████████████| 542kB 4.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mglearn) (3.2.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.22.2.post1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.1.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from mglearn) (7.1.2)\n","Requirement already satisfied: cycler in /usr/local/lib/python3.7/dist-packages (from mglearn) (0.10.0)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from mglearn) (2.4.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from mglearn) (1.0.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mglearn) (1.3.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mglearn) (1.4.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->mglearn) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler->mglearn) (1.15.0)\n","Building wheels for collected packages: mglearn\n","  Building wheel for mglearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=021b86081908ccd6cde0ddbcc1b628d3fe4def2d1951336f859919dfbe16890a\n","  Stored in directory: /root/.cache/pip/wheels/eb/a6/ea/a6a3716233fa62fc561259b5cb1e28f79e9ff3592c0adac5f0\n","Successfully built mglearn\n","Installing collected packages: mglearn\n","Successfully installed mglearn-0.1.9\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iuHoO82Y4ZQ4"},"source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.datasets import make_classification\n","from sklearn import tree\n","\n","import mglearn\n","\n","from matplotlib import pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRWFxJnS4ZQ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623995958771,"user_tz":-540,"elapsed":250,"user":{"displayName":"Potter Harry","photoUrl":"","userId":"17463850288633486562"}},"outputId":"2c0ed095-d5af-4466-85ca-d3f0a8cc1354"},"source":["X, y = make_classification(n_samples=1000, n_features=4,\n","                           n_informative=2, n_redundant=0,\n","                           random_state=0, shuffle=False)\n","clf = RandomForestClassifier(n_estimators=5, random_state=0)\n","clf.fit(X, y)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=5,\n","                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"2cnqcvFk4ZQ-","colab":{"base_uri":"https://localhost:8080/","height":502,"output_embedded_package_id":"1l-UNzDByTaFbaMl237FpRjiO6qoLMrJW"},"executionInfo":{"status":"ok","timestamp":1623996009636,"user_tz":-540,"elapsed":47247,"user":{"displayName":"Potter Harry","photoUrl":"","userId":"17463850288633486562"}},"outputId":"e543fa7c-bad1-419a-bf04-9963f19587d5"},"source":["fig, axes = plt.subplots(nrows = 1,ncols = 5,figsize = (30,10), dpi=900)\n","for index in range(0, 5):\n","    tree.plot_tree(clf.estimators_[index], filled = True, ax=axes[index])\n","    axes[index].set_title('Estimator: ' + str(index), fontsize = 20)\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"VGFunuyB4ZRC"},"source":["유방암 데이터를 불러와서 암 발생 여부를 예측하기 위한 Random Forest를 설계해보겠습니다."]},{"cell_type":"code","metadata":{"id":"3gDi7CgZ4ZRC"},"source":["cancer = load_breast_cancer()\n","X_train, X_test, y_train, y_test = train_test_split(cancer['data'], cancer['target'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5aLHaY-u4ZRF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623996332224,"user_tz":-540,"elapsed":5,"user":{"displayName":"Potter Harry","photoUrl":"","userId":"17463850288633486562"}},"outputId":"cde2e196-3a45-40a3-fe6c-2eb557253128"},"source":["clf = RandomForestClassifier(n_estimators=10, random_state=0)\n","clf.fit(X_train, y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=10,\n","                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"1MRuT5EX4ZRI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623996335262,"user_tz":-540,"elapsed":248,"user":{"displayName":"Potter Harry","photoUrl":"","userId":"17463850288633486562"}},"outputId":"d27113e2-baf2-4626-d755-c0d8d284a43a"},"source":["predict = clf.predict(X_test)\n","print(accuracy_score(y_test, predict))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.9790209790209791\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WtdetMNt4ZRK"},"source":["# 실습"]},{"cell_type":"code","metadata":{"id":"batFryvr4ZRL"},"source":["estimator = range(2, 11)\n","accuracy = [] # estimator(Deicision Tree의 개수)를 변경해보면서 그 때의 accuray를 리스트에 추가하세요"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"znNeNUHR4ZRO"},"source":["# 이곳에 Random Forest 모델을 설계하고 estimator에 따른 정확도를 accuracy 리스트 추가하세요.\n","# RandomForestClassifier()의 argument 중 하나인 n_estimators를 변경하면 됩니다.\n","# clf = RandomForestClassifier(n_estimators=?, random_state=0)\n","# n_estimatiors의 변화에 따른 accuracy를 그래프로 표현하시오\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dA6MXEp_ugQX"},"source":[""],"execution_count":null,"outputs":[]}]}